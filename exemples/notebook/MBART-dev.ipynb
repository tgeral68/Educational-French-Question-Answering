{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d619a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/people/gerald/Documents/repositories/Educational-French-Question-Answering\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd94971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import evaluate\n",
    "import random\n",
    "from src.data_utils.pb_corpus import FQAGPBDataset\n",
    "from src.data_utils.corpus import MixedDataset, KeyMapDataset\n",
    "from src.model.mbart_qg import MBARTQGDataLoaderCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d2a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['EFQADATA'] = '/people/gerald/Documents/repositories/Educational-French-Question-Answering/dataset'\n",
    "os.environ['QA_LOG'] = \"/data/workdir/gerald/log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee4ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_folder = os.path.expandvars(\"$EFQADATA/source\")\n",
    "datasets_name = [\"squad-en-en.pb.json\",\"fquad-fr-fr.pb.json\"]\n",
    "datasets = {}\n",
    "\n",
    "split = \"train\"\n",
    "\n",
    "for dataset_name in datasets_name: \n",
    "    with open(os.path.join(data_folder, dataset_name)) as f:\n",
    "        data = json.load(f)\n",
    "        datasets[dataset_name.split('.')[0]] = FQAGPBDataset(data['train'], sampler = lambda x : [x[random.randint(0, len(x) - 1)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda9181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = KeyMapDataset(MixedDataset(*datasets.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9f7054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_default': True,\n",
       " 'id': 0,\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to <hl>Saint Bernadette Soubirous<hl> in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question_type': 'NONE',\n",
       " 'input_lang': 250008,\n",
       " 'output_lang': 250008,\n",
       " 'index': 0,\n",
       " 'dataset_index': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762c184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d065fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl  = DataLoader(md, batch_size = 2, shuffle=True, collate_fn=MBARTQGDataLoaderCollator(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fb34e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[250008,  77168,    214,     10,  10336,    150,    592,   5423,     99,\n",
       "          131466,   4523,   1392,    450,    509, 151552,    390,    581,  38436,\n",
       "           57699,    237,     44,   3630,    111, 158036,  26177,      9,  58052,\n",
       "            5423,      7,    111,    756,   1733,    830,  10542, 121447,     70,\n",
       "           57119,   4935,   7156,  20413,     70,   6003,  86345,    678,  49191,\n",
       "               9,   1511,      5,   3311, 187016,    214,     10,  40575, 113857,\n",
       "             450, 121447,     70,   7156,   6338,    538,  40859,   8108,   6863,\n",
       "           72761, 105416,  17365,      4,  20413,     70,   6003,  86345, 100512,\n",
       "            1632,    111,     70,  10846,  13036,  67967,   7156,      7,     23,\n",
       "              70,   2665,  32070,     47,  71864,     10,     95,    344,      5,\n",
       "            4426,   8266,   2740,     58,  14535,  31199,      7,     23,   7270,\n",
       "              58,  16093,   8266,   2740, 100512,     70,  17164,     25,      7,\n",
       "          167375, 116287,    214,  11001,      4,  16320,   6048,     99,  14012,\n",
       "           43606,     98,     70, 211441,   9903,    805,      5,    360,  27997,\n",
       "           10542, 121447,     70,  98352,   1363,   7156,  41649,    583,  79428,\n",
       "               4,     10,  42486,    111,  28560,      7,    390,  22104,      7,\n",
       "            1295,  10542,     25,      7,  17164,  67967,    527,  87747,  13703,\n",
       "               5,  41649,    583,  79428, 181653,  22759,  11001,      7,      4,\n",
       "            6626,    111,   3129, 116287,    297,  28032,     70,   2663, 214075,\n",
       "             111,     70,   9903,    805,     12,     44,  30248,   2408,     58,\n",
       "             136,     44,    441,  67367,    740,  10542,   2843,   8951,    297,\n",
       "              10,   1346,    111,     70,   5701,   9351,    450,   9882,    297,\n",
       "              99,     70,   1324, 113501,   3847,   8129,     23, 114122, 242810,\n",
       "               9,   2420,  20051, 180975,      6, 193022,   1830, 241599,  59671,\n",
       "           49119,      7,      5,      2],\n",
       "         [250008,  18763, 158978,    115,    939,    509,  58136,    100,     70,\n",
       "           11737,   1631,      4,   3129,  77443,   2684,  34844,     23,     70,\n",
       "            4122,    271,    111,     70,   4426,   8266,   2740,  91127,    257,\n",
       "             262,  48448,  16093,   8266,   2740,      5,   1529,   7068,    509,\n",
       "           44183,    237, 185256, 116338, 111517,     47,   9082,   4727,  23825,\n",
       "           10437,      4, 126140, 127873,    111, 112006,      5,    360,  60775,\n",
       "               4,    764,  42938,    297,     23,     70,  34735,    214,    111,\n",
       "              70,  38663,  11994,     22,  27034,    674,     23,  17955,      4,\n",
       "             391,      5,    441,      5, 106073,    764,    509,  26548,     70,\n",
       "           61972,  39958,  26548,     70,  52129,      7,    136,  37515,    538,\n",
       "          115992,     71,   4727,  23825,  10437,  26548,  35971,     10,   3835,\n",
       "           31486,     23,    442,      4,    764,  14432,  54397,     70, 126140,\n",
       "              25,      7,  51521,  45559,  13416,      4,     22,  31004,    214,\n",
       "            4727,  23825,  10437,     25,      7,  55080,      5,      2,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]]),\n",
       " 'labels': tensor([[250008,   4865,    509,     70,   2663,  11001,   5773,     70,   7156,\n",
       "              44, 156378,     70,   6003,  86345,  38843,      2],\n",
       "         [250008,   4865,  19732,   7228,   1631,  58136,  34844,     23,    903,\n",
       "           14922,     32,      2,      1,      1,      1,      1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc299f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from src.model.mbart_qg import MBARTQG, MBARTQGDataLoaderCollator\n",
    "from src.eval_utils.evaluate_utils import HFMetric, MultiHFMetric\n",
    "\n",
    "import spacy\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "class SpacyTokenizer():\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"fr_core_news_lg\")\n",
    "    def __call__(self, x):\n",
    "        return [t.text for t in self.nlp.tokenizer(x)]\n",
    "st = SpacyTokenizer()\n",
    "validation_metrics = MultiHFMetric(\n",
    "    sacrebleu = HFMetric('sacrebleu', lambda x : x['score'], tokenize = 'intl'),\n",
    "    rouge = HFMetric('rouge', lambda x : x['rougeL'], tokenizer = st)\n",
    ")\n",
    "\n",
    "os.environ['EFQADATA'] = '/people/gerald/Documents/repositories/Educational-French-Question-Answering/dataset'\n",
    "data_folder = os.path.expandvars(\"$EFQADATA/source\")\n",
    "train_datasets_name = [\"squad-en-en.pb.json\",\"fquad-fr-fr.pb.json\"]\n",
    "valid_datasets_name = [\"fquad-fr-fr.pb.json\"]\n",
    "train_datasets = {}\n",
    "valid_datasets = {}\n",
    "\n",
    "for dataset_name in train_datasets_name: \n",
    "    with open(os.path.join(data_folder, dataset_name)) as f:\n",
    "        il, ol = dataset_name.split('.')[0].split('-')[-2], dataset_name.split('.')[0].split('-')[-1]\n",
    "        data = json.load(f)\n",
    "        train_datasets[dataset_name.split('.')[0]] = FQAGPBDataset(\n",
    "            data[\"train\"],\n",
    "            sampler = lambda x : [x[random.randint(0, len(x) - 1)]],\n",
    "            input_lang = il, output_lang = ol\n",
    "        )\n",
    "for dataset_name in valid_datasets_name: \n",
    "    with open(os.path.join(data_folder, dataset_name)) as f:\n",
    "        il, ol = dataset_name.split('.')[0].split('-')[-2], dataset_name.split('.')[0].split('-')[-1]\n",
    "        data = json.load(f)\n",
    "        valid_datasets[dataset_name.split('.')[0]] = FQAGPBDataset(\n",
    "            data[\"valid\"],\n",
    "            sampler = lambda x : [x[random.randint(0, len(x) - 1)]],\n",
    "            input_lang = il, output_lang = ol\n",
    "        )\n",
    "\n",
    "model = MBARTQG(\n",
    "    pretrained_name = \"facebook/mbart-large-50-many-to-many-mmt\",\n",
    "    fixed_encoder = True,\n",
    "    validation_callback = validation_metrics\n",
    ")\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=os.path.expandvars(\"$QA_LOG\"), name=\"test\")\n",
    "#tb_logger.log_hyperparams(vars(args))\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "train_dl  = DataLoader(KeyMapDataset(MixedDataset(*train_datasets.values())), batch_size = 2, shuffle=True, num_workers=2, collate_fn=MBARTQGDataLoaderCollator(model.tokenizer))\n",
    "valid_dl  = DataLoader(KeyMapDataset(MixedDataset(*valid_datasets.values())), batch_size = 2, shuffle=False, num_workers=2, collate_fn=MBARTQGDataLoaderCollator(model.tokenizer))\n",
    "\n",
    "\n",
    "checkpoint_callback_val_loss = ModelCheckpoint(monitor='val/loss', save_top_k=2, mode=\"min\", filename=\"val-loss-checkpoint-{epoch:02d}-{val_loss:.2f}\")\n",
    "checkpoint_callback_val_sacrebleu = ModelCheckpoint(monitor='val/sacrebleu', save_top_k=2, mode=\"max\", filename=\"val-sacrebleu-checkpoint-{epoch:02d}-{val_loss:.2f}\")\n",
    "checkpoint_callback_val_rouge = ModelCheckpoint(monitor='val/rouge', save_top_k=2, mode=\"max\", filename=\"val-rouge-checkpoint-{epoch:02d}-{val_loss:.2f}\")\n",
    "\n",
    "callbacks = [\n",
    "    lr_monitor,\n",
    "    checkpoint_callback_val_loss,\n",
    "    checkpoint_callback_val_rouge,\n",
    "    checkpoint_callback_val_sacrebleu\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab229ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/people/gerald/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1766: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=2)`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: /data/workdir/gerald/log/test\n",
      "/people/gerald/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/torch/optim/adamw.py:91: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(AdamW, self).__init__(params, defaults)\n",
      "\n",
      "  | Name  | Type                          | Params\n",
      "--------------------------------------------------------\n",
      "0 | model | MBartForConditionalGeneration | 610 M \n",
      "--------------------------------------------------------\n",
      "610 M     Trainable params\n",
      "0         Non-trainable params\n",
      "610 M     Total params\n",
      "2,443.522 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/people/gerald/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/people/gerald/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 200 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Les deux tableaus sont décrits par des documents contemporains à leur création mais ils ne le font que indirectement car ils concernent principalement  La Vierge aux rochers. De ce fait, ils demeurent des sujets de speculation pour les chercheurs quant à leur statut de première ou de deuxième version de l'œuvre, leur création, leur attribution, leur datation, leur exact disposition sur le retable et les raisons qui ont poussé à leurs modifications au cours de la période — notamment en ce qui concerne la couleur du fond.\", 'Les deux tableaus sont décrits par des  documents contemporains à leur création, mais ceux-ci ne le font que indirectement car ils concernent principalement La Vierge aux rochers.'] ['Que concerne principalement les documents?', 'Par quoi sont décrit les deux tableaux?']\n",
      "[\"Les deux tableaus sont décrits par des documents contemporains à leur création, mais ils ne le font que indirectement, car ils concernent principalement La Vierge aux rochers. Ainsi, ils demeurent    pour les chercheurs sur leur statut de première ou deuxième version de l'œuvre, leur création, leur attribution, leur datation, leur exact disposition sur le retable et les raisons qui ont poussé à leurs modifications au cours de la période — notamment en ce qui concerne la couleur du fond.\", \"Les deux panneaux présentent de nombreuses similitudes : chacun comporte un seul personnage exposé en pied, qui se tient dans un niche en trompe-l'œil proposant les mêmes dégradés de gris. Les personnages setiennent en appui sur leur jambe  et avancent leur pied gauche vers le spectateur. Des ailes s'ouvrent légèrement dans leur dos, qui indiquent leur nature d'ange. Les longs et bouclés, ils sont vêtus d'une longue robe de couleur dont le col est rond pour l'un et square pour l'autre. Chacun tient un instrument de musique qu'il semble jouer. Les différences entrent dans l'instrument qu'ils jouent, leur posture pour le faire ainsi que l'aspect et la position de leur tête. Ainsi, l'ange en vert joue de la lira da braccio; il semble frotter l'\"] [\"Quels types d'objets sont les deux tableaux aux yeux des chercheurs?\", 'Sur quelle jambe les personnages se tiennent-t-ils?']\n",
      "\n",
      "\n",
      " [{'generated_text': [\"Les deux tableaus sont décrits par des documents contemporains à leur création mais ils ne le font que indirectement car ils concernent principalement  La Vierge aux rochers. De ce fait, ils demeurent des sujets de speculation pour les chercheurs quant à leur statut de première ou de deuxième version de l'œuvre, leur création, leur attribution, leur datation, leur exact disposition sur le retable et les raisons qui ont poussé à leurs modifications au cours de la période — notamment en ce qui concerne la couleur du fond.\", 'Les deux tableaus sont décrits par des  documents contemporains à leur création, mais ceux-ci ne le font que indirectement car ils concernent principalement La Vierge aux rochers.'], 'ground_truth_text': ['Que concerne principalement les documents?', 'Par quoi sont décrit les deux tableaux?']}, {'generated_text': [\"Les deux tableaus sont décrits par des documents contemporains à leur création, mais ils ne le font que indirectement, car ils concernent principalement La Vierge aux rochers. Ainsi, ils demeurent    pour les chercheurs sur leur statut de première ou deuxième version de l'œuvre, leur création, leur attribution, leur datation, leur exact disposition sur le retable et les raisons qui ont poussé à leurs modifications au cours de la période — notamment en ce qui concerne la couleur du fond.\", \"Les deux panneaux présentent de nombreuses similitudes : chacun comporte un seul personnage exposé en pied, qui se tient dans un niche en trompe-l'œil proposant les mêmes dégradés de gris. Les personnages setiennent en appui sur leur jambe  et avancent leur pied gauche vers le spectateur. Des ailes s'ouvrent légèrement dans leur dos, qui indiquent leur nature d'ange. Les longs et bouclés, ils sont vêtus d'une longue robe de couleur dont le col est rond pour l'un et square pour l'autre. Chacun tient un instrument de musique qu'il semble jouer. Les différences entrent dans l'instrument qu'ils jouent, leur posture pour le faire ainsi que l'aspect et la position de leur tête. Ainsi, l'ange en vert joue de la lira da braccio; il semble frotter l'\"], 'ground_truth_text': [\"Quels types d'objets sont les deux tableaux aux yeux des chercheurs?\", 'Sur quelle jambe les personnages se tiennent-t-ils?']}] \n",
      "\n",
      " ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/people/gerald/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324fba3e063f4cc98bd1191f7cb67d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=tb_logger, \n",
    "    log_every_n_steps=100, \n",
    "    callbacks=callbacks, \n",
    "    enable_progress_bar=True,\n",
    "    limit_train_batches=10000, \n",
    "    max_epochs=250, \n",
    "    accumulate_grad_batches=64,\n",
    "    accelerator='cpu'\n",
    ")\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dl,\n",
    "    valid_dl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91167a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cadee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
