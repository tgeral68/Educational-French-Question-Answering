{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5364ff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/people/gerald/Documents/repositories/Educational-French-Question-Answering\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd94971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import evaluate\n",
    "import random\n",
    "from src.data_utils.pb_corpus import FQAGPBDataset\n",
    "from src.data_utils.corpus import MixedDataset, KeyMapDataset\n",
    "from src.model.mbart_qg import MBARTQGCollateTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee4ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['EFQADATA'] = '/people/gerald/Documents/repositories/Educational-French-Question-Answering/dataset'\n",
    "data_folder = os.path.expandvars(\"$EFQADATA/source\")\n",
    "datasets_name = [\"squad.pb.json\",\"fquad.pb.json\"]\n",
    "datasets = {}\n",
    "\n",
    "split = \"train\"\n",
    "\n",
    "for dataset_name in datasets_name: \n",
    "    with open(os.path.join(data_folder, dataset_name)) as f:\n",
    "        data = json.load(f)\n",
    "        datasets[dataset_name.split('.')[0]] = FQAGPBDataset(data['train'], sampler = lambda x : [x[random.randint(0, len(x) - 1)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda9181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = KeyMapDataset(MixedDataset(*datasets.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50ee253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_default': True,\n",
       " 'id': 0,\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to <hl>Saint Bernadette Soubirous<hl> in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question_type': 'NONE',\n",
       " 'input_lang': 250008,\n",
       " 'output_lang': 250008,\n",
       " 'index': 0,\n",
       " 'dataset_index': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1fe359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "896f31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl  = DataLoader(md, batch_size = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7062caac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_default': tensor([True, True]),\n",
       " 'id': tensor([39612, 36479]),\n",
       " 'question': ['Who is the mascot of Northwestern Athletics?',\n",
       "  'Who marketed epinephrine?'],\n",
       " 'context': ['The mascot of Northwestern Athletics is <hl>Willie the Wildcat<hl>. The first mascot, however, was a live, caged bear cub from the Lincoln Park Zoo named Furpaw who was brought to the playing field on the day of a game to greet the fans. But after a losing season, the team, deciding that Furpaw was to blame for its misfortune, banished him from campus forever. Willie the Wildcat made his debut in 1933 first as a logo, and then in three dimensions in 1947, when members of the Alpha Delta fraternity dressed as wildcats during a Homecoming Parade. The Northwestern University Marching Band (NUMB) performs at all home football games and leads cheers in the student section and performs the Alma Mater at the end of the game.',\n",
       "  'By the 1890s the profound effect of adrenal extracts on many different tissue types had been discovered, setting off a search both for the mechanism of chemical signalling and efforts to exploit these observations for the development of new drugs. The blood pressure raising and vasoconstrictive effects of adrenal extracts were of particular interest to surgeons as hemostatic agents and as treatment for shock, and a number of companies developed products based on adrenal extracts containing varying purities of the active substance. In 1897 John Abel of Johns Hopkins University identified the active principle as epinephrine, which he isolated in an impure state as the sulfate salt. Industrial chemist Jokichi Takamine later developed a method for obtaining epinephrine in a pure state, and licensed the technology to Parke Davis. <hl>Parke Davis<hl> marketed epinephrine under the trade name Adrenalin. Injected epinephrine proved to be especially efficacious for the acute treatment of asthma attacks, and an inhaled version was sold in the United States until 2011 (Primatene Mist). By 1929 epinephrine had been formulated into an inhaler for use in the treatment of nasal congestion.'],\n",
       " 'question_type': ['NONE', 'NONE'],\n",
       " 'input_lang': tensor([250008, 250008]),\n",
       " 'output_lang': tensor([250008, 250008]),\n",
       " 'index': tensor([39612, 36479]),\n",
       " 'dataset_index': tensor([0, 0])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "842e1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bf36482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMBARTQGCollateTokenizer():\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, batch : dict) -> dict:\n",
    "        print({for i in batch)\n",
    "        source = self.tokenizer(batch['context'], return_tensors=\"pt\",  padding='longest', truncation=True, max_length=512)\n",
    "        target = self.tokenizer(batch['question'], return_tensors=\"pt\",  padding='longest', truncation=True, max_length=512)\n",
    "\n",
    "        source_input_ids = source.input_ids\n",
    "        target_input_ids = target.input_ids\n",
    "\n",
    "        source_input_ids[:, 0] = batch[\"input_lang\"]\n",
    "        target_input_ids[:, 0] = batch[\"output_lang\"]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": source_input_ids,\n",
    "            \"attention_mask\": source.attention_mask,\n",
    "            \"labels\": target_input_ids\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98dc58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl  = DataLoader(md, batch_size = 2, shuffle=True, collate_fn=TMBARTQGCollateTokenizer(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6c4b6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'is_default': True, 'id': 64640, 'question': \"In addition to the head and abdomen, what is the other major section of an insect's body?\", 'context': 'Insects (from Latin insectum, a calque of Greek ἔντομον [éntomon], \"cut into sections\") are a class of invertebrates within the arthropod phylum that have a chitinous exoskeleton, a three-part body (head, <hl>thorax<hl> and abdomen), three pairs of jointed legs, compound eyes and one pair of antennae. They are the most diverse group of animals on the planet, including more than a million described species and representing more than half of all known living organisms. The number of extant species is estimated at between six and ten million, and potentially represent over 90% of the differing animal life forms on Earth. Insects may be found in nearly all environments, although only a small number of species reside in the oceans, a habitat dominated by another arthropod group, crustaceans.', 'question_type': 'NONE', 'input_lang': 250008, 'output_lang': 250008, 'index': 64640, 'dataset_index': 0}, {'is_default': True, 'id': 79730, 'question': 'Which states belong to the British-Irish Council?', 'context': 'Another body established under the Good Friday Agreement, the British–Irish Council, is made up of <hl>all of the states and territories of the British Isles<hl>. The British–Irish Parliamentary Assembly (Irish: Tionól Pharlaiminteach na Breataine agus na hÉireann) predates the British–Irish Council and was established in 1990. Originally it comprised 25 members of the Oireachtas, the Irish parliament, and 25 members of the parliament of the United Kingdom, with the purpose of building mutual understanding between members of both legislatures. Since then the role and scope of the body has been expanded to include representatives from the Scottish Parliament, the National Assembly for Wales, the Northern Ireland Assembly, the States of Jersey, the States of Guernsey and the High Court of Tynwald (Isle of Man).', 'question_type': 'NONE', 'input_lang': 250008, 'output_lang': 250008, 'index': 79730, 'dataset_index': 0}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_173402/1659275654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/annotationbob/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_173402/1076252403.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22669265",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn  = MBARTQGCollateTokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bacfd8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[250008,     62,   1202,   2271,  69988,     13,   5426,     83, 137567,\n",
       "           77546,  11034,   3501,     10,   1202,  26551,    136,      8,  13158,\n",
       "            4778, 117396, 130732,  31075,      5,     62,   1202,   2271,  69988,\n",
       "              13,     15,    289,    991,  51529,    237,     10,   4426,   8266,\n",
       "            2740,  10248,   3025,   2271,  69988,     13,  16093,   8266,   2740,\n",
       "              16, 114864,   6626,    707,   1286,  31913,      7,     47,      6,\n",
       "          127219,     67,   1829,   6867,      4, 134477,     13,  10821,   6626,\n",
       "               9,   7514,   1202,    136,  18215, 179965,      7,      5,   3293,\n",
       "              83,  27983, 163846,    297,    390,     70,   4527,    111,     10,\n",
       "            6024,  38496,   6226,  25072,     15,     11,   9879,  29367, 113068,\n",
       "             136,  11782,  24365,   5426,     16,    707,    390,     10,  21373,\n",
       "             351,      9,  58905,  29367,   6024,  38496,   3540,  41159,      6,\n",
       "           55720,  69819,     23,  12638,   1202,   2271,  69988,    214,  25072,\n",
       "               5, 110196,      4,  55556, 136912,      7,    765,  75723,  16274,\n",
       "             297,  89160,  80934,      7,    390,      6, 190358,  48716,  19085,\n",
       "            1202,   2271,  69988,    214,   1829,   1467,      9,  77007,  86685,\n",
       "               5,      2,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1],\n",
       "         [250008,  19597,   5103,    115,  49425,     13,  94815,      4,    199,\n",
       "           46698,  51432,     40,  73390,   5824,     18,      4,    456,  51588,\n",
       "            1236,  97629,    674,    224, 172388,    393, 101133,   7162,      5,\n",
       "             357,    729,   5016,      4,    199,  46698,  51432,      8,   5976,\n",
       "           34290,  71064,    660,     82,     51, 180449,    113,    437,  90113,\n",
       "             253,   5103,      8,    729,   2525,      5,    339,     25,   8355,\n",
       "           11056,   6224,    393, 101133,    944,      8,   5631,  40491,      4,\n",
       "            9896,   4170,     22,    729,   4046,      4,    437, 119033,    253,\n",
       "            4426,   8266,   2740,    188,    223,    199,  14880,  10840,    115,\n",
       "           11146,  16093,   8266,   2740, 122327, 146581,     21,  67078,    115,\n",
       "           11146,    393, 101133,    944,     82,  47587,    660,  23414,    253,\n",
       "             224,  48373,  75690,    927, 132210,      7,      5,   1734, 134046,\n",
       "             196,  25352,    613,     21,  79897,    393, 101133,    944,      4,\n",
       "              96,     25, 229231,    393, 101133,    944,     82,     96,     25,\n",
       "           70052,    224,   3050, 101133,   7162,      5,    357, 196208,      4,\n",
       "              96,     25,  10545,    446, 183964,  10082,    708,  42414,     51,\n",
       "               6, 138903,   1940,  92899,  18211,     21,  12404,      9,    188,\n",
       "            1803,   5097,      8,     96,     25, 229231,      4,     82,  91995,\n",
       "              95,  76733,     82,     95,  16568,    224,    393, 101133,   7162,\n",
       "            1609,    199,   9782,  15032,      7,  72851,   1212,     82, 125567,\n",
       "             944,      5,    891,  52268,     41,   3948,  11610,      8,   4191,\n",
       "              90,     41,     96,     25,    191,  14768,  57465,    104,     25,\n",
       "            2305,   6563,   7162,   2045,   3193,      7,    613,  47749,    366,\n",
       "             199,  10255,   4439,      5,    357,    543,    963,      4, 141425,\n",
       "            1208,  52777,  33085,     13,     51,      6, 138903,  80986,    660,\n",
       "             773,  39043,  29096,   2970,   3050, 101133,   7162,      5,      2]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[250008,   4865,     83,     10,   1202,      9,   2271,  69988,     13,\n",
       "            2843,  51529,    237,     32,      2,      1],\n",
       "         [250008,     62,    569,    437, 119033,     96,     25,   8355,  11056,\n",
       "            6224,      8,   5631,  40491,    705,      2]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn(next(iter(dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de31bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
